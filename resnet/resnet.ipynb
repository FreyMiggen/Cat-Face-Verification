{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2442ffc3-e459-485b-9dd8-1db77b205c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7b5a5bef-e69d-4393-95f7-f9f4fa40a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base=tf.keras.applications.ResNet50V2(include_top=False,\n",
    "                                             weights='imagenet',\n",
    "                                            input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5784e65-27be-4bab-a7fc-aadb8a56989e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_8[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e554a97-4dae-4b18-8a5a-8402cea603f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv1_pad\n",
      "2 conv1_conv\n",
      "3 pool1_pad\n",
      "4 pool1_pool\n",
      "5 conv2_block1_preact_bn\n",
      "6 conv2_block1_preact_relu\n",
      "7 conv2_block1_1_conv\n",
      "8 conv2_block1_1_bn\n",
      "9 conv2_block1_1_relu\n",
      "10 conv2_block1_2_pad\n",
      "11 conv2_block1_2_conv\n",
      "12 conv2_block1_2_bn\n",
      "13 conv2_block1_2_relu\n",
      "14 conv2_block1_0_conv\n",
      "15 conv2_block1_3_conv\n",
      "16 conv2_block1_out\n",
      "17 conv2_block2_preact_bn\n",
      "18 conv2_block2_preact_relu\n",
      "19 conv2_block2_1_conv\n",
      "20 conv2_block2_1_bn\n",
      "21 conv2_block2_1_relu\n",
      "22 conv2_block2_2_pad\n",
      "23 conv2_block2_2_conv\n",
      "24 conv2_block2_2_bn\n",
      "25 conv2_block2_2_relu\n",
      "26 conv2_block2_3_conv\n",
      "27 conv2_block2_out\n",
      "28 conv2_block3_preact_bn\n",
      "29 conv2_block3_preact_relu\n",
      "30 conv2_block3_1_conv\n",
      "31 conv2_block3_1_bn\n",
      "32 conv2_block3_1_relu\n",
      "33 conv2_block3_2_pad\n",
      "34 conv2_block3_2_conv\n",
      "35 conv2_block3_2_bn\n",
      "36 conv2_block3_2_relu\n",
      "37 max_pooling2d_6\n",
      "38 conv2_block3_3_conv\n",
      "39 conv2_block3_out\n",
      "40 conv3_block1_preact_bn\n",
      "41 conv3_block1_preact_relu\n",
      "42 conv3_block1_1_conv\n",
      "43 conv3_block1_1_bn\n",
      "44 conv3_block1_1_relu\n",
      "45 conv3_block1_2_pad\n",
      "46 conv3_block1_2_conv\n",
      "47 conv3_block1_2_bn\n",
      "48 conv3_block1_2_relu\n",
      "49 conv3_block1_0_conv\n",
      "50 conv3_block1_3_conv\n",
      "51 conv3_block1_out\n",
      "52 conv3_block2_preact_bn\n",
      "53 conv3_block2_preact_relu\n",
      "54 conv3_block2_1_conv\n",
      "55 conv3_block2_1_bn\n",
      "56 conv3_block2_1_relu\n",
      "57 conv3_block2_2_pad\n",
      "58 conv3_block2_2_conv\n",
      "59 conv3_block2_2_bn\n",
      "60 conv3_block2_2_relu\n",
      "61 conv3_block2_3_conv\n",
      "62 conv3_block2_out\n",
      "63 conv3_block3_preact_bn\n",
      "64 conv3_block3_preact_relu\n",
      "65 conv3_block3_1_conv\n",
      "66 conv3_block3_1_bn\n",
      "67 conv3_block3_1_relu\n",
      "68 conv3_block3_2_pad\n",
      "69 conv3_block3_2_conv\n",
      "70 conv3_block3_2_bn\n",
      "71 conv3_block3_2_relu\n",
      "72 conv3_block3_3_conv\n",
      "73 conv3_block3_out\n",
      "74 conv3_block4_preact_bn\n",
      "75 conv3_block4_preact_relu\n",
      "76 conv3_block4_1_conv\n",
      "77 conv3_block4_1_bn\n",
      "78 conv3_block4_1_relu\n",
      "79 conv3_block4_2_pad\n",
      "80 conv3_block4_2_conv\n",
      "81 conv3_block4_2_bn\n",
      "82 conv3_block4_2_relu\n",
      "83 max_pooling2d_7\n",
      "84 conv3_block4_3_conv\n",
      "85 conv3_block4_out\n",
      "86 conv4_block1_preact_bn\n",
      "87 conv4_block1_preact_relu\n",
      "88 conv4_block1_1_conv\n",
      "89 conv4_block1_1_bn\n",
      "90 conv4_block1_1_relu\n",
      "91 conv4_block1_2_pad\n",
      "92 conv4_block1_2_conv\n",
      "93 conv4_block1_2_bn\n",
      "94 conv4_block1_2_relu\n",
      "95 conv4_block1_0_conv\n",
      "96 conv4_block1_3_conv\n",
      "97 conv4_block1_out\n",
      "98 conv4_block2_preact_bn\n",
      "99 conv4_block2_preact_relu\n",
      "100 conv4_block2_1_conv\n",
      "101 conv4_block2_1_bn\n",
      "102 conv4_block2_1_relu\n",
      "103 conv4_block2_2_pad\n",
      "104 conv4_block2_2_conv\n",
      "105 conv4_block2_2_bn\n",
      "106 conv4_block2_2_relu\n",
      "107 conv4_block2_3_conv\n",
      "108 conv4_block2_out\n",
      "109 conv4_block3_preact_bn\n",
      "110 conv4_block3_preact_relu\n",
      "111 conv4_block3_1_conv\n",
      "112 conv4_block3_1_bn\n",
      "113 conv4_block3_1_relu\n",
      "114 conv4_block3_2_pad\n",
      "115 conv4_block3_2_conv\n",
      "116 conv4_block3_2_bn\n",
      "117 conv4_block3_2_relu\n",
      "118 conv4_block3_3_conv\n",
      "119 conv4_block3_out\n",
      "120 conv4_block4_preact_bn\n",
      "121 conv4_block4_preact_relu\n",
      "122 conv4_block4_1_conv\n",
      "123 conv4_block4_1_bn\n",
      "124 conv4_block4_1_relu\n",
      "125 conv4_block4_2_pad\n",
      "126 conv4_block4_2_conv\n",
      "127 conv4_block4_2_bn\n",
      "128 conv4_block4_2_relu\n",
      "129 conv4_block4_3_conv\n",
      "130 conv4_block4_out\n",
      "131 conv4_block5_preact_bn\n",
      "132 conv4_block5_preact_relu\n",
      "133 conv4_block5_1_conv\n",
      "134 conv4_block5_1_bn\n",
      "135 conv4_block5_1_relu\n",
      "136 conv4_block5_2_pad\n",
      "137 conv4_block5_2_conv\n",
      "138 conv4_block5_2_bn\n",
      "139 conv4_block5_2_relu\n",
      "140 conv4_block5_3_conv\n",
      "141 conv4_block5_out\n",
      "142 conv4_block6_preact_bn\n",
      "143 conv4_block6_preact_relu\n",
      "144 conv4_block6_1_conv\n",
      "145 conv4_block6_1_bn\n",
      "146 conv4_block6_1_relu\n",
      "147 conv4_block6_2_pad\n",
      "148 conv4_block6_2_conv\n",
      "149 conv4_block6_2_bn\n",
      "150 conv4_block6_2_relu\n",
      "151 max_pooling2d_8\n",
      "152 conv4_block6_3_conv\n",
      "153 conv4_block6_out\n",
      "154 conv5_block1_preact_bn\n",
      "155 conv5_block1_preact_relu\n",
      "156 conv5_block1_1_conv\n",
      "157 conv5_block1_1_bn\n",
      "158 conv5_block1_1_relu\n",
      "159 conv5_block1_2_pad\n",
      "160 conv5_block1_2_conv\n",
      "161 conv5_block1_2_bn\n",
      "162 conv5_block1_2_relu\n",
      "163 conv5_block1_0_conv\n",
      "164 conv5_block1_3_conv\n",
      "165 conv5_block1_out\n",
      "166 conv5_block2_preact_bn\n",
      "167 conv5_block2_preact_relu\n",
      "168 conv5_block2_1_conv\n",
      "169 conv5_block2_1_bn\n",
      "170 conv5_block2_1_relu\n",
      "171 conv5_block2_2_pad\n",
      "172 conv5_block2_2_conv\n",
      "173 conv5_block2_2_bn\n",
      "174 conv5_block2_2_relu\n",
      "175 conv5_block2_3_conv\n",
      "176 conv5_block2_out\n",
      "177 conv5_block3_preact_bn\n",
      "178 conv5_block3_preact_relu\n",
      "179 conv5_block3_1_conv\n",
      "180 conv5_block3_1_bn\n",
      "181 conv5_block3_1_relu\n",
      "182 conv5_block3_2_pad\n",
      "183 conv5_block3_2_conv\n",
      "184 conv5_block3_2_bn\n",
      "185 conv5_block3_2_relu\n",
      "186 conv5_block3_3_conv\n",
      "187 conv5_block3_out\n",
      "188 post_bn\n",
      "189 post_relu\n"
     ]
    }
   ],
   "source": [
    "layers=resnet_base.layers\n",
    "for i,layer in enumerate(layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2bf9b8be-d9e5-40a7-a16a-808077ace888",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base.trainable=True\n",
    "layers=resnet_base.layers\n",
    "for layer in layers[:98]:\n",
    "    layer.trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd53a188-b362-4d94-aef1-d1353edca48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "inputs=Input(shape=(224,224,3))\n",
    "x=resnet_base(inputs)\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x= Dense(512,activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x= Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(32, use_bias=False)(x)\n",
    "outputs = Lambda(lambda x: tf.math.l2_normalize(x,axis=-1))(x)\n",
    "model = tf.keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "57834f36-24b3-42fa-83c6-1fda7fb74e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm = tf.linalg.diag_part(dot_product)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.expand_dims(square_norm, 0) - 2.0 * dot_product + tf.expand_dims(square_norm, 1)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.cast(tf.equal(distances, 0.0),dtype=tf.float32)\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "    \n",
    "    # REGULARIZATION: ADD THE DOT PRODUCT TERM\n",
    "    return distances, dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ab1038b1-df80-4eb8-8e4a-db6944667d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "30b332c3-888c-4147-974e-adaa4c8bbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_all_triplet_loss(labels, embeddings, margin=0.2,alpha=0, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    We generate all the valid triplets and average the loss over the positive ones.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist,dot_product = _pairwise_distances(embeddings, squared=squared)\n",
    "    \n",
    "    #REGULARIZATION: compute regulazation term so  that dot_pro_expand[i,j,k] contains embed_i(T)*emb_k\n",
    "    dot_pro_expand=tf.reshape(tf.tile(dot_product,(1,labels.shape[0])),[labels.shape[0],labels.shape[0],labels.shape[0]])\n",
    "\n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\n",
    "\n",
    "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
    "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
    "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
    "    # and the 2nd (batch_size, 1, batch_size)\n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.cast(mask,dtype=tf.float32)\n",
    "    triplet_loss = tf.multiply(mask, triplet_loss)\n",
    "    \n",
    "    #REGULARIZATION:put to zero to invalid triplets\n",
    "    regularizer=tf.multiply(mask,dot_pro_expand)\n",
    "    M1=tf.math.square(regularizer)\n",
    "    M2=tf.maximum(M1-(1/32),0)\n",
    "\n",
    "    # Remove negative losses (i.e. the easy triplets)\n",
    "    triplet_loss = tf.maximum(triplet_loss, 0.0)\n",
    "    #REGULARIZATION: add regularization term\n",
    "    triplet_loss=triplet_loss+alpha*(M1+M2)\n",
    "\n",
    "    # Count number of positive triplets (where triplet_loss > 0)\n",
    "    valid_triplets = tf.cast(tf.greater(triplet_loss, 1e-16),dtype=tf.float32)\n",
    "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\n",
    "\n",
    "    # Get final mean triplet loss over the positive valid triplets\n",
    "    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "90038c9f-87b5-4f51-9d8c-8d3f02d2ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_triplet(labels,embeddings,margin=0.2,squared=False):\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist,dot_product = _pairwise_distances(embeddings, squared=squared)\n",
    "    \n",
    "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
    "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\n",
    "    \n",
    "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "\n",
    "    # Put to zero the invalid triplets\n",
    "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
    "    mask = _get_triplet_mask(labels)\n",
    "    mask = tf.cast(mask,dtype=tf.float32)\n",
    "    triplet_loss = tf.multiply(mask, triplet_loss)\n",
    "    #triplet_loss = tf.maximum(triplet_loss, 0.0)\n",
    "    \n",
    "    #TRIPLET WITH LOSS<0\n",
    "    \n",
    "    negative_triplets=tf.cast(tf.less(triplet_loss,0),tf.float32)\n",
    "    num_negative_triplets=tf.math.reduce_sum(negative_triplets)\n",
    "    num_valid_triplets = tf.reduce_sum(mask)\n",
    "    return num_negative_triplets/num_valid_triplets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a1d57-7c8a-4731-8ed4-8eb4bc6ce3cb",
   "metadata": {},
   "source": [
    "## build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3e585b8-1a73-4204-9804-c83023ea7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 files belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir='0'\n",
    "dataset=tf.keras.preprocessing.image_dataset_from_directory(directory=data_dir,\n",
    "                                                           image_size=(224,224),\n",
    "                                                           batch_size=64,\n",
    "                                                           color_mode='rgb',\n",
    "                                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a377ae18-11b7-49a0-ab84-a5361a632ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img,label):\n",
    "    img=tf.keras.applications.resnet_v2.preprocess_input(img)\n",
    "    img=tf.image.random_brightness(img,0.2)\n",
    "    img=tf.image.random_saturation(img,2,5)\n",
    "    img=tf.image.random_flip_left_right(img)\n",
    "    return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dfa38c08-5678-4801-8788-fb94f9d15459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.map(process_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01656655-8186-4f54-8119-8b53f9324c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn=batch_all_triplet_loss\n",
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cff5d2e8-2d43-49e1-b71b-fc6afec2d756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('resnet/resnet_50v2_emb_32_margin_02_alpha_03_20_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f38b3c87-a29b-452a-8610-64f5e26e0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0:  0.064292625\n",
      "Accuracy at epoch 0:  0.86004716\n",
      "Loss at epoch 1:  0.058241505\n",
      "Accuracy at epoch 1:  0.85692936\n",
      "Loss at epoch 2:  0.057082552\n",
      "Accuracy at epoch 2:  0.83918315\n",
      "Loss at epoch 3:  0.055276573\n",
      "Accuracy at epoch 3:  0.86459965\n",
      "Loss at epoch 4:  0.05034845\n",
      "Accuracy at epoch 4:  0.8717963\n",
      "Loss at epoch 5:  0.04862778\n",
      "Accuracy at epoch 5:  0.89900666\n",
      "Loss at epoch 6:  0.049111098\n",
      "Accuracy at epoch 6:  0.88254625\n",
      "Loss at epoch 7:  0.044388894\n",
      "Accuracy at epoch 7:  0.90381306\n",
      "Loss at epoch 8:  0.043723863\n",
      "Accuracy at epoch 8:  0.9050712\n",
      "Loss at epoch 9:  0.039893907\n",
      "Accuracy at epoch 9:  0.9219176\n",
      "Loss at epoch 10:  0.037842467\n",
      "Accuracy at epoch 10:  0.92454356\n",
      "Loss at epoch 11:  0.039614573\n",
      "Accuracy at epoch 11:  0.92839164\n",
      "Loss at epoch 12:  0.036539074\n",
      "Accuracy at epoch 12:  0.9342897\n",
      "Loss at epoch 13:  0.03318927\n",
      "Accuracy at epoch 13:  0.95339274\n",
      "Loss at epoch 14:  0.033800725\n",
      "Accuracy at epoch 14:  0.9462933\n",
      "Loss at epoch 15:  0.034880582\n",
      "Accuracy at epoch 15:  0.94216466\n",
      "Loss at epoch 16:  0.029837392\n",
      "Accuracy at epoch 16:  0.9596081\n",
      "Loss at epoch 17:  0.030660631\n",
      "Accuracy at epoch 17:  0.9606183\n",
      "Loss at epoch 18:  0.031089248\n",
      "Accuracy at epoch 18:  0.9573049\n",
      "Loss at epoch 19:  0.029370015\n",
      "Accuracy at epoch 19:  0.96580225\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss=[]\n",
    "    running_acc=[]\n",
    "    for x_batch,y_batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            embeddings=model(x_batch,training=True)\n",
    "            loss=batch_all_triplet_loss(y_batch,embeddings,margin=0.2,alpha=0.5)\n",
    "            acc=accuracy_triplet(y_batch,embeddings,margin=0.2)\n",
    "        gradients=tape.gradient(loss,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_weights))\n",
    "        running_loss.append(loss)\n",
    "        running_acc.append(acc)\n",
    "    #calculate mean loss\n",
    "    print(f'Loss at epoch {epoch}: ',np.mean(running_loss))\n",
    "    print(f'Accuracy at epoch {epoch}: ',np.mean(running_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "135d5e2d-ec48-42b8-8234-34101712f910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('resnet/resnet_50v2_emb_32_margin_02_alpha_03_40_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee522ac7-5813-4906-b4fa-bf1c0132eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triples(digit_indices):\n",
    "    '''Positive and negative triple creation.\n",
    "    Each triple include two images of same label (anchor and postive) and one image of different label.\n",
    "    '''\n",
    "    \n",
    "    classes=len(digit_indices)\n",
    "    triples = []\n",
    "    \n",
    "    # n is min length of an array of indices with a specific value (0->9)\n",
    "    n = min([len(digit_indices[d]) for d in range(classes)]) - 1\n",
    "    \n",
    "    #digit_indices[d]: contains all indices of images of the same label\n",
    "    for d in range(classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "           \n",
    "            inc = random.randrange(1, 32)\n",
    "            dn = (d + inc) % 32\n",
    "            z3 = digit_indices[dn][i]\n",
    "            triples += [[z1,z2,z3]]\n",
    "            \n",
    "    return np.array(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "821a8c39-0ddc-4951-a338-d874720ec8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_for_test(image_path):\n",
    "    image = tf.keras.utils.load_img(image_path)\n",
    "    input_arr = tf.keras.utils.img_to_array(image)\n",
    "    input_arr=input_arr/255.0\n",
    "    input_arr=tf.image.resize(input_arr,(224,224))\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "    predictions = model.predict(input_arr)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4681bb61-3604-4a96-96d9-4518865be8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(emb_1,emb_2):\n",
    "    dist=tf.math.subtract(emb_1,emb_2)\n",
    "    dist=tf.math.square(dist)\n",
    "    dist=tf.math.reduce_sum(dist)\n",
    "    dist=tf.math.sqrt(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83de2085-f9ea-45e0-8cc9-39624c1699ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the list that store all image paths\n",
    "import os\n",
    "folder='0'\n",
    "sub=os.listdir(folder)\n",
    "cat_indices=[0 for i in range(len(sub))]\n",
    "sub=os.listdir(folder)\n",
    "for i in range(len(sub)):\n",
    "    dir=os.path.join(folder,sub[i])\n",
    "    image_list=os.listdir(dir)\n",
    "    img_path_list=[os.path.join(dir,fname) for fname in image_list]\n",
    "    cat_indices[i]=img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb263b54-c4e4-4061-b875-a715f2bbd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset=create_triples(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9a1a882-5443-4ec1-953f-b5a80fd7862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('resnet/resnet_50v2_emb_32_margin_02_alpha_05_20_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e806e30c-ebc7-45b8-92de-46e707162be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(100):\n",
    "    anchor=processed_for_test(testset[i][0])\n",
    "    pos=processed_for_test(testset[i][1])\n",
    "    neg=processed_for_test(testset[i][2])\n",
    "    pos_dist=compute_distance(anchor,pos)\n",
    "    neg_dist=compute_distance(anchor,neg)\n",
    "    # print(\"At triplet\",i)\n",
    "    # print(\"post dis:\",pos_dist)\n",
    "    # print('neg dist:',neg_dist)\n",
    "    if neg_dist-pos_dist>=0.2:\n",
    "        count+=1\n",
    "    else:\n",
    "        print(\"Wrong at triplet\",i)\n",
    "        print(f\"pos_dist: {pos_dist}\")\n",
    "        print(f\"neg_dist: {neg_dist}\")\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "15b5219d-77b8-4487-9ed9-b870df5feb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "201cf580-f3f8-4720-a4a7-5fe79ab28a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model('resnet/resnet_50v2_emb_32_margin_02_alpha_05_40_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8da878cf-e0f6-4294-9dd9-d4ac0473eaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At triplet 0\n",
      "post dis: tf.Tensor(0.3052278, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5500395, shape=(), dtype=float32)\n",
      "At triplet 1\n",
      "post dis: tf.Tensor(0.4026877, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4345411, shape=(), dtype=float32)\n",
      "At triplet 2\n",
      "post dis: tf.Tensor(0.30101714, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.319791, shape=(), dtype=float32)\n",
      "At triplet 3\n",
      "post dis: tf.Tensor(0.34418467, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.2312732, shape=(), dtype=float32)\n",
      "At triplet 4\n",
      "post dis: tf.Tensor(0.32187292, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3663648, shape=(), dtype=float32)\n",
      "At triplet 5\n",
      "post dis: tf.Tensor(0.36797768, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3462706, shape=(), dtype=float32)\n",
      "At triplet 6\n",
      "post dis: tf.Tensor(0.25719932, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.225972, shape=(), dtype=float32)\n",
      "At triplet 7\n",
      "post dis: tf.Tensor(0.3849241, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.48154, shape=(), dtype=float32)\n",
      "At triplet 8\n",
      "post dis: tf.Tensor(0.5324913, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.2461296, shape=(), dtype=float32)\n",
      "At triplet 9\n",
      "post dis: tf.Tensor(0.61195374, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4891473, shape=(), dtype=float32)\n",
      "At triplet 10\n",
      "post dis: tf.Tensor(0.67301023, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4896104, shape=(), dtype=float32)\n",
      "At triplet 11\n",
      "post dis: tf.Tensor(0.5236007, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3603234, shape=(), dtype=float32)\n",
      "At triplet 12\n",
      "post dis: tf.Tensor(0.43122378, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5518686, shape=(), dtype=float32)\n",
      "At triplet 13\n",
      "post dis: tf.Tensor(0.5156434, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5181825, shape=(), dtype=float32)\n",
      "At triplet 14\n",
      "post dis: tf.Tensor(0.70656353, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3987406, shape=(), dtype=float32)\n",
      "At triplet 15\n",
      "post dis: tf.Tensor(0.42438835, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5005337, shape=(), dtype=float32)\n",
      "At triplet 16\n",
      "post dis: tf.Tensor(0.5971508, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4114702, shape=(), dtype=float32)\n",
      "At triplet 17\n",
      "post dis: tf.Tensor(0.47554272, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4500623, shape=(), dtype=float32)\n",
      "At triplet 18\n",
      "post dis: tf.Tensor(0.29058826, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4043999, shape=(), dtype=float32)\n",
      "At triplet 19\n",
      "post dis: tf.Tensor(0.3006151, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.459798, shape=(), dtype=float32)\n",
      "At triplet 20\n",
      "post dis: tf.Tensor(0.73947275, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.1749636, shape=(), dtype=float32)\n",
      "At triplet 21\n",
      "post dis: tf.Tensor(0.9119003, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4203417, shape=(), dtype=float32)\n",
      "At triplet 22\n",
      "post dis: tf.Tensor(0.8762829, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.1621983, shape=(), dtype=float32)\n",
      "At triplet 23\n",
      "post dis: tf.Tensor(0.6957726, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4449085, shape=(), dtype=float32)\n",
      "At triplet 24\n",
      "post dis: tf.Tensor(0.583791, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5437881, shape=(), dtype=float32)\n",
      "At triplet 25\n",
      "post dis: tf.Tensor(0.9040541, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4929585, shape=(), dtype=float32)\n",
      "At triplet 26\n",
      "post dis: tf.Tensor(0.7528437, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(0.48155427, shape=(), dtype=float32)\n",
      "At triplet 27\n",
      "post dis: tf.Tensor(0.49244893, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4482529, shape=(), dtype=float32)\n",
      "At triplet 28\n",
      "post dis: tf.Tensor(0.36814815, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3648987, shape=(), dtype=float32)\n",
      "At triplet 29\n",
      "post dis: tf.Tensor(0.24305886, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4391981, shape=(), dtype=float32)\n",
      "At triplet 30\n",
      "post dis: tf.Tensor(0.2494877, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(0.574133, shape=(), dtype=float32)\n",
      "At triplet 31\n",
      "post dis: tf.Tensor(0.4899677, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4242076, shape=(), dtype=float32)\n",
      "At triplet 32\n",
      "post dis: tf.Tensor(0.3253681, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4869862, shape=(), dtype=float32)\n",
      "At triplet 33\n",
      "post dis: tf.Tensor(0.51394653, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5961177, shape=(), dtype=float32)\n",
      "At triplet 34\n",
      "post dis: tf.Tensor(0.20128414, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.493151, shape=(), dtype=float32)\n",
      "At triplet 35\n",
      "post dis: tf.Tensor(0.23889627, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5238632, shape=(), dtype=float32)\n",
      "At triplet 36\n",
      "post dis: tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3099673, shape=(), dtype=float32)\n",
      "At triplet 37\n",
      "post dis: tf.Tensor(0.17455609, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3744857, shape=(), dtype=float32)\n",
      "At triplet 38\n",
      "post dis: tf.Tensor(0.20680203, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3126805, shape=(), dtype=float32)\n",
      "At triplet 39\n",
      "post dis: tf.Tensor(0.16333324, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4574157, shape=(), dtype=float32)\n",
      "At triplet 40\n",
      "post dis: tf.Tensor(0.24099275, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5683306, shape=(), dtype=float32)\n",
      "At triplet 41\n",
      "post dis: tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4176097, shape=(), dtype=float32)\n",
      "At triplet 42\n",
      "post dis: tf.Tensor(0.34936613, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.4668562, shape=(), dtype=float32)\n",
      "At triplet 43\n",
      "post dis: tf.Tensor(0.29634264, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.2285061, shape=(), dtype=float32)\n",
      "At triplet 44\n",
      "post dis: tf.Tensor(0.2937483, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3729224, shape=(), dtype=float32)\n",
      "At triplet 45\n",
      "post dis: tf.Tensor(0.2372098, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.215253, shape=(), dtype=float32)\n",
      "At triplet 46\n",
      "post dis: tf.Tensor(0.121206015, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3945196, shape=(), dtype=float32)\n",
      "At triplet 47\n",
      "post dis: tf.Tensor(0.26520482, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3018085, shape=(), dtype=float32)\n",
      "At triplet 48\n",
      "post dis: tf.Tensor(0.18548563, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.5258867, shape=(), dtype=float32)\n",
      "At triplet 49\n",
      "post dis: tf.Tensor(0.24124983, shape=(), dtype=float32)\n",
      "neg dist: tf.Tensor(1.3728595, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(50):\n",
    "    anchor=processed_for_test(testset[i][0])\n",
    "    pos=processed_for_test(testset[i][1])\n",
    "    neg=processed_for_test(testset[i][2])\n",
    "    pos_dist=compute_distance(anchor,pos)\n",
    "    neg_dist=compute_distance(anchor,neg)\n",
    "    print(\"At triplet\",i)\n",
    "    print(\"post dis:\",pos_dist)\n",
    "    print('neg dist:',neg_dist)\n",
    "    # if neg_dist-pos_dist>=0.2:\n",
    "    #     count+=1\n",
    "    # else:\n",
    "    #     print(\"Wrong at triplet\",i)\n",
    "    #     print(f\"pos_dist: {pos_dist}\")\n",
    "    #     print(f\"neg_dist: {neg_dist}\")\n",
    "    #     print(\"!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad73b0-f622-4b5f-a3a1-811e4b2ccaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(sub_dir):\n",
    "    data_dir=sub_dir\n",
    "    dataset=tf.keras.preprocessing.image_dataset_from_directory(directory=data_dir,\n",
    "                                                           image_size=(224,224),\n",
    "                                                           batch_size=64,\n",
    "                                                           color_mode='rgb',\n",
    "                                                           )\n",
    "    dataset=dataset.map(process_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
